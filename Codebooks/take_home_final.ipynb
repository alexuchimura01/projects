{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Political Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>political_affiliation</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Some college</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, very religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Female</td>\n",
       "      <td>58</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>College degree</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes, very religious</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High school or less</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>64</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>High school or less</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>325</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Some college</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>328</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Graduate degree</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>329</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Some college</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>332</td>\n",
       "      <td>Female</td>\n",
       "      <td>51</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Graduate degree</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, very religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>335</td>\n",
       "      <td>Male</td>\n",
       "      <td>67</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High school or less</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_num      Q1  Q2 political_affiliation            Q4  \\\n",
       "0         1    Male  53           Independent       Liberal   \n",
       "1         5  Female  66           Independent  Conservative   \n",
       "2         7  Female  58              Democrat       Liberal   \n",
       "3         8    Male  55           Independent      Moderate   \n",
       "4         9    Male  64            Republican  Conservative   \n",
       "..      ...     ...  ..                   ...           ...   \n",
       "164     325    Male  21            Republican  Conservative   \n",
       "165     328  Female  41            Republican       Liberal   \n",
       "166     329    Male  60            Republican  Conservative   \n",
       "167     332  Female  51            Republican  Conservative   \n",
       "168     335    Male  67            Republican      Moderate   \n",
       "\n",
       "                      Q5     Q6   Q7   Q8   Q9                      Q10  \\\n",
       "0         College degree  Black   No   No   No  Yes, somewhat religious   \n",
       "1           Some college  White  Yes   No  Yes      Yes, very religious   \n",
       "2         College degree  White   No   No   No      Yes, very religious   \n",
       "3    High school or less  White  Yes  Yes  Yes  Yes, somewhat religious   \n",
       "4    High school or less  White  Yes  Yes  Yes                       No   \n",
       "..                   ...    ...  ...  ...  ...                      ...   \n",
       "164         Some college  White  Yes   No  Yes                       No   \n",
       "165      Graduate degree  White  Yes  Yes  Yes  Yes, somewhat religious   \n",
       "166         Some college  White  Yes  Yes  Yes  Yes, somewhat religious   \n",
       "167      Graduate degree  White  Yes  Yes  Yes      Yes, very religious   \n",
       "168  High school or less  White  Yes  Yes  Yes  Yes, somewhat religious   \n",
       "\n",
       "            Q11  Q12  Q13                    Q14  Q15  Q16  Q17  Q18  \n",
       "0    Pro-Choice   No   No  Behave no differently    5    2    5   No  \n",
       "1      Pro-life  Yes  Yes           Less Willing    4    5    4   No  \n",
       "2    Pro-Choice   No   No  Behave no differently    5    1    4  Yes  \n",
       "3      Pro-life  Yes  Yes           Less Willing    4    5    4  Yes  \n",
       "4      Pro-life   No   No  Behave no differently    5    1    1  Yes  \n",
       "..          ...  ...  ...                    ...  ...  ...  ...  ...  \n",
       "164  Pro-Choice  Yes   No           Less Willing    5    2    5   No  \n",
       "165  Pro-Choice  Yes   No           Less Willing    5    2    2   No  \n",
       "166    Pro-life   No  Yes  Behave no differently    5    5    4  Yes  \n",
       "167    Pro-life  Yes   No           Less Willing    2    5    1   No  \n",
       "168    Pro-life  Yes   No  Behave no differently    5    5    4  Yes  \n",
       "\n",
       "[169 rows x 19 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in data\n",
    "raw_data = pd.read_csv(\"C:/Users/alexa/OneDrive/Documentos/VSCode Folder/GSB544_Computing_and_ML/Kaggle_Comp/Data/CAH-201803-train.csv\")\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Data was already very clean and I decided not to change column headers as I had key to reference which columns correlated to which survey questions. Each question seemed to have some relevance. Coefficient analysis below shows that every explanatory variable has somewhat of a signifiicant impact in predicting political affiliation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_num                    int64\n",
       "Q1                       object\n",
       "Q2                        int64\n",
       "political_affiliation    object\n",
       "Q4                       object\n",
       "Q5                       object\n",
       "Q6                       object\n",
       "Q7                       object\n",
       "Q8                       object\n",
       "Q9                       object\n",
       "Q10                      object\n",
       "Q11                      object\n",
       "Q12                      object\n",
       "Q13                      object\n",
       "Q14                      object\n",
       "Q15                       int64\n",
       "Q16                       int64\n",
       "Q17                       int64\n",
       "Q18                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model \n",
    "Other models were implemented with various combinations of predictor variables, different parameters, interaction variables, and polynomial transformations, but this model yielded the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logit__C': 1, 'logit__class_weight': 'balanced', 'logit__l1_ratio': 0.1, 'logit__penalty': 'l1', 'logit__solver': 'liblinear'}\n",
      "Best Accuracy: 0.6274509803921569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "1200 fits failed out of a total of 1800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "133 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "120 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "121 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "62 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "116 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.34331551        nan 0.34919786 0.49679144        nan        nan\n",
      "        nan        nan        nan 0.3311943         nan 0.34919786\n",
      " 0.3372549         nan        nan        nan        nan        nan\n",
      " 0.34919786        nan 0.34919786 0.34331551        nan        nan\n",
      "        nan        nan        nan 0.34331551        nan 0.34919786\n",
      " 0.33743316        nan        nan        nan        nan        nan\n",
      " 0.33137255        nan 0.34919786 0.49090909        nan        nan\n",
      "        nan        nan        nan 0.33743316        nan 0.34919786\n",
      " 0.33137255        nan        nan        nan        nan        nan\n",
      " 0.3254902         nan 0.34919786 0.34919786        nan        nan\n",
      "        nan        nan        nan 0.33743316        nan 0.34919786\n",
      " 0.33137255        nan        nan        nan        nan        nan\n",
      " 0.53279857        nan 0.53885918 0.59803922        nan        nan\n",
      "        nan        nan        nan 0.53279857        nan 0.53885918\n",
      " 0.54456328        nan        nan        nan        nan        nan\n",
      " 0.53279857        nan 0.53885918 0.53279857        nan        nan\n",
      "        nan        nan        nan 0.53279857        nan 0.53885918\n",
      " 0.53885918        nan        nan        nan        nan        nan\n",
      " 0.53885918        nan 0.55062389 0.60392157        nan        nan\n",
      "        nan        nan        nan 0.53885918        nan 0.55062389\n",
      " 0.55632799        nan        nan        nan        nan        nan\n",
      " 0.53885918        nan 0.55062389 0.54456328        nan        nan\n",
      "        nan        nan        nan 0.53885918        nan 0.55062389\n",
      " 0.53279857        nan        nan        nan        nan        nan\n",
      " 0.61568627        nan 0.62156863 0.61550802        nan        nan\n",
      "        nan        nan        nan 0.61568627        nan 0.62156863\n",
      " 0.62156863        nan        nan        nan        nan        nan\n",
      " 0.61568627        nan 0.62156863 0.61568627        nan        nan\n",
      "        nan        nan        nan 0.61568627        nan 0.62156863\n",
      " 0.61568627        nan        nan        nan        nan        nan\n",
      " 0.62156863        nan 0.62745098 0.62139037        nan        nan\n",
      "        nan        nan        nan 0.62156863        nan 0.62745098\n",
      " 0.62139037        nan        nan        nan        nan        nan\n",
      " 0.62156863        nan 0.62745098 0.62139037        nan        nan\n",
      "        nan        nan        nan 0.62156863        nan 0.62745098\n",
      " 0.61550802        nan        nan        nan        nan        nan\n",
      " 0.59180036        nan 0.59786096 0.585918          nan        nan\n",
      "        nan        nan        nan 0.59180036        nan 0.59786096\n",
      " 0.585918          nan        nan        nan        nan        nan\n",
      " 0.59180036        nan 0.59786096 0.59180036        nan        nan\n",
      "        nan        nan        nan 0.59180036        nan 0.59786096\n",
      " 0.59180036        nan        nan        nan        nan        nan\n",
      " 0.59786096        nan 0.59786096 0.59786096        nan        nan\n",
      "        nan        nan        nan 0.60374332        nan 0.59786096\n",
      " 0.59786096        nan        nan        nan        nan        nan\n",
      " 0.60374332        nan 0.59786096 0.59786096        nan        nan\n",
      "        nan        nan        nan 0.59786096        nan 0.59786096\n",
      " 0.59786096        nan        nan        nan        nan        nan\n",
      " 0.585918          nan 0.60980392 0.585918          nan        nan\n",
      "        nan        nan        nan 0.585918          nan 0.60980392\n",
      " 0.585918          nan        nan        nan        nan        nan\n",
      " 0.585918          nan 0.60980392 0.585918          nan        nan\n",
      "        nan        nan        nan 0.585918          nan 0.60980392\n",
      " 0.585918          nan        nan        nan        nan        nan\n",
      " 0.59180036        nan 0.60980392 0.59180036        nan        nan\n",
      "        nan        nan        nan 0.59180036        nan 0.60980392\n",
      " 0.59180036        nan        nan        nan        nan        nan\n",
      " 0.59180036        nan 0.60980392 0.59180036        nan        nan\n",
      "        nan        nan        nan 0.59180036        nan 0.60980392\n",
      " 0.59180036        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initial attempt at using everything for logit model\n",
    "\n",
    "X = raw_data.drop(['id_num', 'political_affiliation'], axis=1)\n",
    "y = raw_data['political_affiliation']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [('preprocessing', ct),\n",
    "     ('logit', LogisticRegression()),]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'logit__C': [0.01, 0.1, 1, 10, 100],       # Inverse of regularization strength\n",
    "    'logit__penalty': ['l1', 'elasticnet', 'none'],  # Type of regularization\n",
    "    'logit__solver': ['saga', 'lbfgs', 'liblinear'],       # Solver\n",
    "    'logit__class_weight': [None, 'balanced'],             # Handle class imbalance\n",
    "    'logit__l1_ratio': [0.1, 0.5, 0.7, 0.9],               # Only for elasticnet penalty\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best Accuracy:\", gscv_fitted.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating predictions on test data \n",
    "Had to create a new CSV file with an added 'political_affiliation_predicted' column on test data for Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>78</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>College degree</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes, very religious</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High school or less</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, very religious</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>More Willing</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High school or less</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, very religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Graduate degree</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High school or less</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>More Willing</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>327</td>\n",
       "      <td>Female</td>\n",
       "      <td>68</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Graduate degree</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes, very religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>330</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>High school or less</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>331</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Latino</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>333</td>\n",
       "      <td>Female</td>\n",
       "      <td>54</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Graduate degree</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Pro-Choice</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Behave no differently</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>334</td>\n",
       "      <td>Male</td>\n",
       "      <td>54</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Some college</td>\n",
       "      <td>Latino</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes, somewhat religious</td>\n",
       "      <td>Pro-life</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Less Willing</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_num      Q1  Q2            Q4                   Q5      Q6   Q7   Q8  \\\n",
       "0         2  Female  78  Conservative       College degree   White  Yes  Yes   \n",
       "1         3    Male  59      Moderate  High school or less   Black  Yes  Yes   \n",
       "2         4    Male  59      Moderate  High school or less   White  Yes   No   \n",
       "3         6    Male  52      Moderate      Graduate degree   White  Yes  Yes   \n",
       "4        11  Female  33      Moderate  High school or less   White   No   No   \n",
       "..      ...     ...  ..           ...                  ...     ...  ...  ...   \n",
       "161     327  Female  68      Moderate      Graduate degree   White  Yes   No   \n",
       "162     330    Male  20      Moderate  High school or less   White  Yes  Yes   \n",
       "163     331    Male  65  Conservative       College degree  Latino  Yes   No   \n",
       "164     333  Female  54      Moderate      Graduate degree   White  Yes   No   \n",
       "165     334    Male  54  Conservative         Some college  Latino  Yes  Yes   \n",
       "\n",
       "      Q9                      Q10         Q11  Q12  Q13  \\\n",
       "0     No      Yes, very religious  Pro-Choice  Yes  Yes   \n",
       "1    Yes      Yes, very religious  Pro-Choice   No   No   \n",
       "2    Yes      Yes, very religious    Pro-life  Yes   No   \n",
       "3    Yes  Yes, somewhat religious  Pro-Choice   No  Yes   \n",
       "4    Yes  Yes, somewhat religious  Pro-Choice   No   No   \n",
       "..   ...                      ...         ...  ...  ...   \n",
       "161   No      Yes, very religious    Pro-life  Yes   No   \n",
       "162  Yes                       No  Pro-Choice   No   No   \n",
       "163   No                       No  Pro-Choice  Yes   No   \n",
       "164   No                       No  Pro-Choice   No   No   \n",
       "165   No  Yes, somewhat religious    Pro-life  Yes  Yes   \n",
       "\n",
       "                       Q14  Q15  Q16  Q17  Q18  \n",
       "0    Behave no differently    4    5    1  Yes  \n",
       "1             More Willing    5    4    5   No  \n",
       "2    Behave no differently    4    5    1  Yes  \n",
       "3             Less Willing    5    4    4   No  \n",
       "4             More Willing    5    5    4  Yes  \n",
       "..                     ...  ...  ...  ...  ...  \n",
       "161  Behave no differently    5    5    2   No  \n",
       "162           Less Willing    5    2    5   No  \n",
       "163  Behave no differently    5    2    1   No  \n",
       "164  Behave no differently    5    1    5  Yes  \n",
       "165           Less Willing    5    1    5   No  \n",
       "\n",
       "[166 rows x 18 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in test data and applying initial attempt to test data\n",
    "test_raw_data = pd.read_csv(\"C:/Users/alexa/OneDrive/Documentos/VSCode Folder/GSB544_Computing_and_ML/Kaggle_Comp/Data/CAH-201803-test.csv\")\n",
    "test_raw_data \n",
    "\n",
    "# pipeline.fit(X, y)\n",
    "\n",
    "final_predictions = pd.DataFrame(\n",
    "    {\"id_num\": test_raw_data['id_num'],\n",
    "    \"political_affiliation_predicted\": pipeline.predict(test_raw_data)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "      <th>political_affiliation_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>327</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>330</td>\n",
       "      <td>Independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>331</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>333</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>334</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_num political_affiliation_predicted\n",
       "0         2                      Republican\n",
       "1         3                        Democrat\n",
       "2         4                        Democrat\n",
       "3         6                      Republican\n",
       "4        11                     Independent\n",
       "..      ...                             ...\n",
       "161     327                        Democrat\n",
       "162     330                     Independent\n",
       "163     331                        Democrat\n",
       "164     333                        Democrat\n",
       "165     334                      Republican\n",
       "\n",
       "[166 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions\n",
    "#for model 1 above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Coefficient Analysis on above model\n",
    "Wanted to examine how each variable influenced political affiliation to see if there were any variables that did not increase accuracy for any given model. We can see that 'dummify__Q5_Some college' has the lowest overall impact with a coef value of 0.108, which is stil large enough to be included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Democrat</th>\n",
       "      <th>Independent</th>\n",
       "      <th>Republican</th>\n",
       "      <th>Overall_Impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummify__Q4_Conservative</th>\n",
       "      <td>-0.992039</td>\n",
       "      <td>-0.297187</td>\n",
       "      <td>1.289226</td>\n",
       "      <td>2.578452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q4_Liberal</th>\n",
       "      <td>0.776302</td>\n",
       "      <td>-0.048345</td>\n",
       "      <td>-0.727957</td>\n",
       "      <td>1.552604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q6_White</th>\n",
       "      <td>-0.622137</td>\n",
       "      <td>0.175390</td>\n",
       "      <td>0.446746</td>\n",
       "      <td>1.244273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q4_Moderate</th>\n",
       "      <td>0.216469</td>\n",
       "      <td>0.345926</td>\n",
       "      <td>-0.562395</td>\n",
       "      <td>1.124791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q10_Yes, very religious</th>\n",
       "      <td>0.524718</td>\n",
       "      <td>-0.058498</td>\n",
       "      <td>-0.466219</td>\n",
       "      <td>1.049436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q6_Black</th>\n",
       "      <td>0.490328</td>\n",
       "      <td>-0.518574</td>\n",
       "      <td>0.028246</td>\n",
       "      <td>1.037148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q6_Asian</th>\n",
       "      <td>-0.082205</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>-0.413795</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q14_Behave no differently</th>\n",
       "      <td>0.466673</td>\n",
       "      <td>-0.053474</td>\n",
       "      <td>-0.413199</td>\n",
       "      <td>0.933345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q5_Graduate degree</th>\n",
       "      <td>-0.212793</td>\n",
       "      <td>-0.226436</td>\n",
       "      <td>0.439228</td>\n",
       "      <td>0.878457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standardize__Q17</th>\n",
       "      <td>-0.244484</td>\n",
       "      <td>0.425446</td>\n",
       "      <td>-0.180962</td>\n",
       "      <td>0.850892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standardize__Q2</th>\n",
       "      <td>0.389541</td>\n",
       "      <td>-0.423966</td>\n",
       "      <td>0.034426</td>\n",
       "      <td>0.847932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q10_Yes, somewhat religious</th>\n",
       "      <td>-0.341366</td>\n",
       "      <td>-0.038443</td>\n",
       "      <td>0.379809</td>\n",
       "      <td>0.759618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q5_High school or less</th>\n",
       "      <td>0.106778</td>\n",
       "      <td>0.270589</td>\n",
       "      <td>-0.377368</td>\n",
       "      <td>0.754735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q11_Pro-life</th>\n",
       "      <td>-0.133566</td>\n",
       "      <td>0.349114</td>\n",
       "      <td>-0.215548</td>\n",
       "      <td>0.698227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q11_Pro-Choice</th>\n",
       "      <td>0.134298</td>\n",
       "      <td>-0.348719</td>\n",
       "      <td>0.214422</td>\n",
       "      <td>0.697439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standardize__Q15</th>\n",
       "      <td>0.330875</td>\n",
       "      <td>-0.039233</td>\n",
       "      <td>-0.291642</td>\n",
       "      <td>0.661749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q14_Less Willing</th>\n",
       "      <td>-0.191168</td>\n",
       "      <td>-0.131362</td>\n",
       "      <td>0.322530</td>\n",
       "      <td>0.645059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q18_No</th>\n",
       "      <td>0.301590</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>-0.310831</td>\n",
       "      <td>0.621661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q18_Yes</th>\n",
       "      <td>-0.300858</td>\n",
       "      <td>-0.008847</td>\n",
       "      <td>0.309704</td>\n",
       "      <td>0.619409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q13_No</th>\n",
       "      <td>0.222391</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>-0.284916</td>\n",
       "      <td>0.569832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q13_Yes</th>\n",
       "      <td>-0.221659</td>\n",
       "      <td>-0.062131</td>\n",
       "      <td>0.283790</td>\n",
       "      <td>0.567579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q14_More Willing</th>\n",
       "      <td>-0.274773</td>\n",
       "      <td>0.185230</td>\n",
       "      <td>0.089543</td>\n",
       "      <td>0.549545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q1_Male</th>\n",
       "      <td>-0.127591</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>-0.124909</td>\n",
       "      <td>0.504999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q1_Female</th>\n",
       "      <td>0.128323</td>\n",
       "      <td>-0.252105</td>\n",
       "      <td>0.123782</td>\n",
       "      <td>0.504211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q6_Latino</th>\n",
       "      <td>0.214745</td>\n",
       "      <td>-0.152422</td>\n",
       "      <td>-0.062323</td>\n",
       "      <td>0.429491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q7_No</th>\n",
       "      <td>0.098373</td>\n",
       "      <td>0.103246</td>\n",
       "      <td>-0.201619</td>\n",
       "      <td>0.403238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q7_Yes</th>\n",
       "      <td>-0.097641</td>\n",
       "      <td>-0.102852</td>\n",
       "      <td>0.200493</td>\n",
       "      <td>0.400986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q9_No</th>\n",
       "      <td>0.195426</td>\n",
       "      <td>-0.106249</td>\n",
       "      <td>-0.089177</td>\n",
       "      <td>0.390853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q9_Yes</th>\n",
       "      <td>-0.194694</td>\n",
       "      <td>0.106644</td>\n",
       "      <td>0.088051</td>\n",
       "      <td>0.389389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q10_No</th>\n",
       "      <td>-0.182619</td>\n",
       "      <td>0.097336</td>\n",
       "      <td>0.085284</td>\n",
       "      <td>0.365239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q5_College degree</th>\n",
       "      <td>0.156882</td>\n",
       "      <td>-0.097991</td>\n",
       "      <td>-0.058891</td>\n",
       "      <td>0.313763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standardize__Q16</th>\n",
       "      <td>-0.135002</td>\n",
       "      <td>0.030049</td>\n",
       "      <td>0.104954</td>\n",
       "      <td>0.270005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q8_No</th>\n",
       "      <td>0.051859</td>\n",
       "      <td>0.082391</td>\n",
       "      <td>-0.134250</td>\n",
       "      <td>0.268499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q8_Yes</th>\n",
       "      <td>-0.051127</td>\n",
       "      <td>-0.081997</td>\n",
       "      <td>0.133123</td>\n",
       "      <td>0.266246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q12_Yes</th>\n",
       "      <td>0.076673</td>\n",
       "      <td>-0.040882</td>\n",
       "      <td>-0.035791</td>\n",
       "      <td>0.153346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q12_No</th>\n",
       "      <td>-0.075941</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.034664</td>\n",
       "      <td>0.151882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummify__Q5_Some college</th>\n",
       "      <td>-0.050135</td>\n",
       "      <td>0.054231</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>0.108463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Democrat  Independent  Republican  \\\n",
       "dummify__Q4_Conservative             -0.992039    -0.297187    1.289226   \n",
       "dummify__Q4_Liberal                   0.776302    -0.048345   -0.727957   \n",
       "dummify__Q6_White                    -0.622137     0.175390    0.446746   \n",
       "dummify__Q4_Moderate                  0.216469     0.345926   -0.562395   \n",
       "dummify__Q10_Yes, very religious      0.524718    -0.058498   -0.466219   \n",
       "dummify__Q6_Black                     0.490328    -0.518574    0.028246   \n",
       "dummify__Q6_Asian                    -0.082205     0.496000   -0.413795   \n",
       "dummify__Q14_Behave no differently    0.466673    -0.053474   -0.413199   \n",
       "dummify__Q5_Graduate degree          -0.212793    -0.226436    0.439228   \n",
       "standardize__Q17                     -0.244484     0.425446   -0.180962   \n",
       "standardize__Q2                       0.389541    -0.423966    0.034426   \n",
       "dummify__Q10_Yes, somewhat religious -0.341366    -0.038443    0.379809   \n",
       "dummify__Q5_High school or less       0.106778     0.270589   -0.377368   \n",
       "dummify__Q11_Pro-life                -0.133566     0.349114   -0.215548   \n",
       "dummify__Q11_Pro-Choice               0.134298    -0.348719    0.214422   \n",
       "standardize__Q15                      0.330875    -0.039233   -0.291642   \n",
       "dummify__Q14_Less Willing            -0.191168    -0.131362    0.322530   \n",
       "dummify__Q18_No                       0.301590     0.009241   -0.310831   \n",
       "dummify__Q18_Yes                     -0.300858    -0.008847    0.309704   \n",
       "dummify__Q13_No                       0.222391     0.062525   -0.284916   \n",
       "dummify__Q13_Yes                     -0.221659    -0.062131    0.283790   \n",
       "dummify__Q14_More Willing            -0.274773     0.185230    0.089543   \n",
       "dummify__Q1_Male                     -0.127591     0.252500   -0.124909   \n",
       "dummify__Q1_Female                    0.128323    -0.252105    0.123782   \n",
       "dummify__Q6_Latino                    0.214745    -0.152422   -0.062323   \n",
       "dummify__Q7_No                        0.098373     0.103246   -0.201619   \n",
       "dummify__Q7_Yes                      -0.097641    -0.102852    0.200493   \n",
       "dummify__Q9_No                        0.195426    -0.106249   -0.089177   \n",
       "dummify__Q9_Yes                      -0.194694     0.106644    0.088051   \n",
       "dummify__Q10_No                      -0.182619     0.097336    0.085284   \n",
       "dummify__Q5_College degree            0.156882    -0.097991   -0.058891   \n",
       "standardize__Q16                     -0.135002     0.030049    0.104954   \n",
       "dummify__Q8_No                        0.051859     0.082391   -0.134250   \n",
       "dummify__Q8_Yes                      -0.051127    -0.081997    0.133123   \n",
       "dummify__Q12_Yes                      0.076673    -0.040882   -0.035791   \n",
       "dummify__Q12_No                      -0.075941     0.041276    0.034664   \n",
       "dummify__Q5_Some college             -0.050135     0.054231   -0.004096   \n",
       "\n",
       "                                      Overall_Impact  \n",
       "dummify__Q4_Conservative                    2.578452  \n",
       "dummify__Q4_Liberal                         1.552604  \n",
       "dummify__Q6_White                           1.244273  \n",
       "dummify__Q4_Moderate                        1.124791  \n",
       "dummify__Q10_Yes, very religious            1.049436  \n",
       "dummify__Q6_Black                           1.037148  \n",
       "dummify__Q6_Asian                           0.992000  \n",
       "dummify__Q14_Behave no differently          0.933345  \n",
       "dummify__Q5_Graduate degree                 0.878457  \n",
       "standardize__Q17                            0.850892  \n",
       "standardize__Q2                             0.847932  \n",
       "dummify__Q10_Yes, somewhat religious        0.759618  \n",
       "dummify__Q5_High school or less             0.754735  \n",
       "dummify__Q11_Pro-life                       0.698227  \n",
       "dummify__Q11_Pro-Choice                     0.697439  \n",
       "standardize__Q15                            0.661749  \n",
       "dummify__Q14_Less Willing                   0.645059  \n",
       "dummify__Q18_No                             0.621661  \n",
       "dummify__Q18_Yes                            0.619409  \n",
       "dummify__Q13_No                             0.569832  \n",
       "dummify__Q13_Yes                            0.567579  \n",
       "dummify__Q14_More Willing                   0.549545  \n",
       "dummify__Q1_Male                            0.504999  \n",
       "dummify__Q1_Female                          0.504211  \n",
       "dummify__Q6_Latino                          0.429491  \n",
       "dummify__Q7_No                              0.403238  \n",
       "dummify__Q7_Yes                             0.400986  \n",
       "dummify__Q9_No                              0.390853  \n",
       "dummify__Q9_Yes                             0.389389  \n",
       "dummify__Q10_No                             0.365239  \n",
       "dummify__Q5_College degree                  0.313763  \n",
       "standardize__Q16                            0.270005  \n",
       "dummify__Q8_No                              0.268499  \n",
       "dummify__Q8_Yes                             0.266246  \n",
       "dummify__Q12_Yes                            0.153346  \n",
       "dummify__Q12_No                             0.151882  \n",
       "dummify__Q5_Some college                    0.108463  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)\n",
    "\n",
    "coefs = pipeline.named_steps[\"logit\"].coef_\n",
    "\n",
    "coefs\n",
    "\n",
    "# Get feature names\n",
    "feature_names = pipeline.named_steps[\"preprocessing\"].get_feature_names_out()\n",
    "\n",
    "# Get coefficients and classes\n",
    "coefs = pipeline.named_steps[\"logit\"].coef_  # Coefficients for each class\n",
    "classes = pipeline.named_steps[\"logit\"].classes_  # Target class names\n",
    "\n",
    "# Create a DataFrame for easy manipulation\n",
    "coefficients_df = pd.DataFrame(coefs.T, index=feature_names, columns=classes)\n",
    "\n",
    "# Calculate overall impact for each feature\n",
    "coefficients_df['Overall_Impact'] = coefficients_df.abs().sum(axis=1)\n",
    "\n",
    "# Sort by overall impact\n",
    "coefficients_df = coefficients_df.sort_values(by='Overall_Impact', ascending=False)\n",
    "\n",
    "coefficients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>PID</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159000</td>\n",
       "      <td>531363010</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9605</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1218</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271900</td>\n",
       "      <td>906203120</td>\n",
       "      <td>90.0</td>\n",
       "      <td>14684</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2196</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137500</td>\n",
       "      <td>916176030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14375</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Timber</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1344</td>\n",
       "      <td>Typ</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248500</td>\n",
       "      <td>528180130</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6472</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>1Story</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1456</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167000</td>\n",
       "      <td>528290030</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9734</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1374</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>220000</td>\n",
       "      <td>906420020</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10041</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1915</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>160000</td>\n",
       "      <td>909129090</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1268</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>225000</td>\n",
       "      <td>528292060</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12460</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2322</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>83000</td>\n",
       "      <td>905426060</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10625</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>835</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>250000</td>\n",
       "      <td>528142020</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8899</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2088</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice        PID  Lot Frontage  Lot Area Street Neighborhood  \\\n",
       "0        159000  531363010          80.0      9605   Pave      SawyerW   \n",
       "1        271900  906203120          90.0     14684   Pave      SawyerW   \n",
       "2        137500  916176030           NaN     14375   Pave       Timber   \n",
       "3        248500  528180130          48.0      6472   Pave      NridgHt   \n",
       "4        167000  528290030          61.0      9734   Pave      Gilbert   \n",
       "...         ...        ...           ...       ...    ...          ...   \n",
       "2192     220000  906420020          80.0     10041   Pave      SawyerW   \n",
       "2193     160000  909129090          70.0      6300   Pave        SWISU   \n",
       "2194     225000  528292060          41.0     12460   Pave      Gilbert   \n",
       "2195      83000  905426060          85.0     10625   Pave      Edwards   \n",
       "2196     250000  528142020          74.0      8899   Pave      NridgHt   \n",
       "\n",
       "     Bldg Type House Style  Overall Qual  Overall Cond  ...  Full Bath  \\\n",
       "0         1Fam      1Story             7             6  ...          1   \n",
       "1         1Fam      1Story             7             7  ...          2   \n",
       "2         1Fam        SLvl             6             6  ...          1   \n",
       "3       TwnhsE      1Story             9             5  ...          2   \n",
       "4         1Fam        SLvl             7             5  ...          2   \n",
       "...        ...         ...           ...           ...  ...        ...   \n",
       "2192      1Fam      2Story             8             5  ...          2   \n",
       "2193      1Fam      1.5Fin             5             4  ...          1   \n",
       "2194      1Fam      2Story             7             5  ...          2   \n",
       "2195      1Fam      1Story             5             5  ...          1   \n",
       "2196      1Fam      2Story             8             5  ...          2   \n",
       "\n",
       "     Half Bath Bedroom AbvGr TotRms AbvGrd Gr Liv Area  Functional  \\\n",
       "0            1             3             6        1218         Typ   \n",
       "1            0             3             7        2196         Typ   \n",
       "2            0             3             7        1344         Typ   \n",
       "3            0             2             6        1456         Typ   \n",
       "4            1             3             7        1374         Typ   \n",
       "...        ...           ...           ...         ...         ...   \n",
       "2192         1             3             8        1915         Typ   \n",
       "2193         1             3             7        1268         Typ   \n",
       "2194         1             4             8        2322         Typ   \n",
       "2195         0             2             5         835         Typ   \n",
       "2196         1             4            10        2088         Typ   \n",
       "\n",
       "      Screen Porch  Pool Area  Yr Sold  Sale Type  \n",
       "0                0          0     2009         WD  \n",
       "1                0          0     2009         WD  \n",
       "2              233          0     2009        COD  \n",
       "3                0          0     2009         WD  \n",
       "4                0          0     2009         WD  \n",
       "...            ...        ...      ...        ...  \n",
       "2192             0          0     2006         WD  \n",
       "2193             0          0     2009         WD  \n",
       "2194             0          0     2008         WD  \n",
       "2195             0          0     2010        COD  \n",
       "2196             0          0     2008         WD  \n",
       "\n",
       "[2197 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_raw = pd.read_csv(\"C:/Users/alexa/OneDrive/Documentos/VSCode Folder/GSB544_Computing_and_ML/Kaggle_Comp/Data/train_new.csv\")\n",
    "house_raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "By looking at the data in the 'data wrangler' extension from VS code, 'Lot Frontage' is the only variable with a large amount of missing values (16% of values). To fill in these missing values, a random forest model uses all other predictors variables to predict lot frontage missing values. Now we have a dataset with only a few missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_without_frontage: (362, 33)\n",
      "Shape of X_missing after alignment: (362, 32)\n",
      "Model RMSE: 17.922856831507772\n",
      "   SalePrice        PID  Lot Frontage  Lot Area Street Neighborhood Bldg Type  \\\n",
      "0     159000  531363010         80.00      9605   Pave      SawyerW      1Fam   \n",
      "1     271900  906203120         90.00     14684   Pave      SawyerW      1Fam   \n",
      "2     137500  916176030         90.13     14375   Pave       Timber      1Fam   \n",
      "3     248500  528180130         48.00      6472   Pave      NridgHt    TwnhsE   \n",
      "4     167000  528290030         61.00      9734   Pave      Gilbert      1Fam   \n",
      "\n",
      "  House Style  Overall Qual  Overall Cond  ...  Full Bath Half Bath  \\\n",
      "0      1Story             7             6  ...          1         1   \n",
      "1      1Story             7             7  ...          2         0   \n",
      "2        SLvl             6             6  ...          1         0   \n",
      "3      1Story             9             5  ...          2         0   \n",
      "4        SLvl             7             5  ...          2         1   \n",
      "\n",
      "  Bedroom AbvGr TotRms AbvGrd Gr Liv Area  Functional  Screen Porch  \\\n",
      "0             3             6        1218         Typ             0   \n",
      "1             3             7        2196         Typ             0   \n",
      "2             3             7        1344         Typ           233   \n",
      "3             2             6        1456         Typ             0   \n",
      "4             3             7        1374         Typ             0   \n",
      "\n",
      "   Pool Area  Yr Sold  Sale Type  \n",
      "0          0     2009         WD  \n",
      "1          0     2009         WD  \n",
      "2          0     2009        COD  \n",
      "3          0     2009         WD  \n",
      "4          0     2009         WD  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# cleaning data to replace missing lot fronatage values with predicted lot frontage values\n",
    "\n",
    "# Step 1: Analyze correlations to determine relevant features\n",
    "# Select only numeric columns for correlation analysis\n",
    "numeric_data = house_raw.select_dtypes(include=[np.number])\n",
    "correlations = numeric_data.corr()\n",
    "lot_frontage_corr = correlations['Lot Frontage'].sort_values(ascending=False)\n",
    "\n",
    "# Select top correlated features (excluding Lot Frontage itself)\n",
    "relevant_features = lot_frontage_corr.index[1:6]\n",
    "\n",
    "# Step 2: Prepare data for modeling\n",
    "# Include only relevant features for modeling, add categorical feature 'Neighborhood'\n",
    "features = list(relevant_features) + ['Neighborhood']\n",
    "data_model = house_raw[features + ['Lot Frontage']].copy()\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "data_model = pd.get_dummies(data_model, columns=['Neighborhood'], drop_first=True)\n",
    "\n",
    "# Split the dataset into rows with and without \"Lot Frontage\"\n",
    "data_with_frontage = data_model.dropna(subset=['Lot Frontage'])\n",
    "data_without_frontage = data_model[data_model['Lot Frontage'].isnull()]\n",
    "\n",
    "# Step 3: Debugging to ensure rows are available for missing data prediction\n",
    "print(\"Shape of data_without_frontage:\", data_without_frontage.shape)\n",
    "\n",
    "# Separate predictors and target for rows with frontage\n",
    "X = data_with_frontage.drop(columns=['Lot Frontage'])\n",
    "y = data_with_frontage['Lot Frontage']\n",
    "\n",
    "# Ensure consistent feature alignment between training and missing data\n",
    "X_missing = data_without_frontage.drop(columns=['Lot Frontage'])\n",
    "X_missing = X_missing.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Debugging output\n",
    "print(\"Shape of X_missing after alignment:\", X_missing.shape)\n",
    "\n",
    "# Step 4: Train and evaluate the model if rows are available\n",
    "if not X_missing.empty:\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the regression model\n",
    "    model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Predict missing \"Lot Frontage\" values\n",
    "    predicted_frontage = model.predict(X_missing)\n",
    "\n",
    "    # Fill the missing values\n",
    "    house_raw.loc[house_raw['Lot Frontage'].isnull(), 'Lot Frontage'] = predicted_frontage\n",
    "\n",
    "    # Display the RMSE and the updated dataset head\n",
    "    print(\"Model RMSE:\", rmse)\n",
    "    print(house_raw.head())\n",
    "else:\n",
    "    print(\"Error: No rows available for prediction. Check preprocessing steps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>PID</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159000</td>\n",
       "      <td>531363010</td>\n",
       "      <td>80.00</td>\n",
       "      <td>9605</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1218</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271900</td>\n",
       "      <td>906203120</td>\n",
       "      <td>90.00</td>\n",
       "      <td>14684</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2196</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137500</td>\n",
       "      <td>916176030</td>\n",
       "      <td>90.13</td>\n",
       "      <td>14375</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Timber</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1344</td>\n",
       "      <td>Typ</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248500</td>\n",
       "      <td>528180130</td>\n",
       "      <td>48.00</td>\n",
       "      <td>6472</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>1Story</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1456</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167000</td>\n",
       "      <td>528290030</td>\n",
       "      <td>61.00</td>\n",
       "      <td>9734</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1374</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>220000</td>\n",
       "      <td>906420020</td>\n",
       "      <td>80.00</td>\n",
       "      <td>10041</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1915</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>160000</td>\n",
       "      <td>909129090</td>\n",
       "      <td>70.00</td>\n",
       "      <td>6300</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1268</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>225000</td>\n",
       "      <td>528292060</td>\n",
       "      <td>41.00</td>\n",
       "      <td>12460</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2322</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>83000</td>\n",
       "      <td>905426060</td>\n",
       "      <td>85.00</td>\n",
       "      <td>10625</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>835</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>250000</td>\n",
       "      <td>528142020</td>\n",
       "      <td>74.00</td>\n",
       "      <td>8899</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2088</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice        PID  Lot Frontage  Lot Area Street Neighborhood  \\\n",
       "0        159000  531363010         80.00      9605   Pave      SawyerW   \n",
       "1        271900  906203120         90.00     14684   Pave      SawyerW   \n",
       "2        137500  916176030         90.13     14375   Pave       Timber   \n",
       "3        248500  528180130         48.00      6472   Pave      NridgHt   \n",
       "4        167000  528290030         61.00      9734   Pave      Gilbert   \n",
       "...         ...        ...           ...       ...    ...          ...   \n",
       "2192     220000  906420020         80.00     10041   Pave      SawyerW   \n",
       "2193     160000  909129090         70.00      6300   Pave        SWISU   \n",
       "2194     225000  528292060         41.00     12460   Pave      Gilbert   \n",
       "2195      83000  905426060         85.00     10625   Pave      Edwards   \n",
       "2196     250000  528142020         74.00      8899   Pave      NridgHt   \n",
       "\n",
       "     Bldg Type House Style  Overall Qual  Overall Cond  ...  Full Bath  \\\n",
       "0         1Fam      1Story             7             6  ...          1   \n",
       "1         1Fam      1Story             7             7  ...          2   \n",
       "2         1Fam        SLvl             6             6  ...          1   \n",
       "3       TwnhsE      1Story             9             5  ...          2   \n",
       "4         1Fam        SLvl             7             5  ...          2   \n",
       "...        ...         ...           ...           ...  ...        ...   \n",
       "2192      1Fam      2Story             8             5  ...          2   \n",
       "2193      1Fam      1.5Fin             5             4  ...          1   \n",
       "2194      1Fam      2Story             7             5  ...          2   \n",
       "2195      1Fam      1Story             5             5  ...          1   \n",
       "2196      1Fam      2Story             8             5  ...          2   \n",
       "\n",
       "     Half Bath Bedroom AbvGr TotRms AbvGrd Gr Liv Area  Functional  \\\n",
       "0            1             3             6        1218         Typ   \n",
       "1            0             3             7        2196         Typ   \n",
       "2            0             3             7        1344         Typ   \n",
       "3            0             2             6        1456         Typ   \n",
       "4            1             3             7        1374         Typ   \n",
       "...        ...           ...           ...         ...         ...   \n",
       "2192         1             3             8        1915         Typ   \n",
       "2193         1             3             7        1268         Typ   \n",
       "2194         1             4             8        2322         Typ   \n",
       "2195         0             2             5         835         Typ   \n",
       "2196         1             4            10        2088         Typ   \n",
       "\n",
       "      Screen Porch  Pool Area  Yr Sold  Sale Type  \n",
       "0                0          0     2009         WD  \n",
       "1                0          0     2009         WD  \n",
       "2              233          0     2009        COD  \n",
       "3                0          0     2009         WD  \n",
       "4                0          0     2009         WD  \n",
       "...            ...        ...      ...        ...  \n",
       "2192             0          0     2006         WD  \n",
       "2193             0          0     2009         WD  \n",
       "2194             0          0     2008         WD  \n",
       "2195             0          0     2010        COD  \n",
       "2196             0          0     2008         WD  \n",
       "\n",
       "[2197 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are dropping the one row with missing values from other predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>PID</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159000</td>\n",
       "      <td>531363010</td>\n",
       "      <td>80.00</td>\n",
       "      <td>9605</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1218</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271900</td>\n",
       "      <td>906203120</td>\n",
       "      <td>90.00</td>\n",
       "      <td>14684</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2196</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137500</td>\n",
       "      <td>916176030</td>\n",
       "      <td>90.13</td>\n",
       "      <td>14375</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Timber</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1344</td>\n",
       "      <td>Typ</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248500</td>\n",
       "      <td>528180130</td>\n",
       "      <td>48.00</td>\n",
       "      <td>6472</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>1Story</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1456</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167000</td>\n",
       "      <td>528290030</td>\n",
       "      <td>61.00</td>\n",
       "      <td>9734</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1374</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>220000</td>\n",
       "      <td>906420020</td>\n",
       "      <td>80.00</td>\n",
       "      <td>10041</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1915</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>160000</td>\n",
       "      <td>909129090</td>\n",
       "      <td>70.00</td>\n",
       "      <td>6300</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1268</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>225000</td>\n",
       "      <td>528292060</td>\n",
       "      <td>41.00</td>\n",
       "      <td>12460</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2322</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>83000</td>\n",
       "      <td>905426060</td>\n",
       "      <td>85.00</td>\n",
       "      <td>10625</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>835</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>COD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>250000</td>\n",
       "      <td>528142020</td>\n",
       "      <td>74.00</td>\n",
       "      <td>8899</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2088</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice        PID  Lot Frontage  Lot Area Street Neighborhood  \\\n",
       "0        159000  531363010         80.00      9605   Pave      SawyerW   \n",
       "1        271900  906203120         90.00     14684   Pave      SawyerW   \n",
       "2        137500  916176030         90.13     14375   Pave       Timber   \n",
       "3        248500  528180130         48.00      6472   Pave      NridgHt   \n",
       "4        167000  528290030         61.00      9734   Pave      Gilbert   \n",
       "...         ...        ...           ...       ...    ...          ...   \n",
       "2192     220000  906420020         80.00     10041   Pave      SawyerW   \n",
       "2193     160000  909129090         70.00      6300   Pave        SWISU   \n",
       "2194     225000  528292060         41.00     12460   Pave      Gilbert   \n",
       "2195      83000  905426060         85.00     10625   Pave      Edwards   \n",
       "2196     250000  528142020         74.00      8899   Pave      NridgHt   \n",
       "\n",
       "     Bldg Type House Style  Overall Qual  Overall Cond  ...  Full Bath  \\\n",
       "0         1Fam      1Story             7             6  ...          1   \n",
       "1         1Fam      1Story             7             7  ...          2   \n",
       "2         1Fam        SLvl             6             6  ...          1   \n",
       "3       TwnhsE      1Story             9             5  ...          2   \n",
       "4         1Fam        SLvl             7             5  ...          2   \n",
       "...        ...         ...           ...           ...  ...        ...   \n",
       "2192      1Fam      2Story             8             5  ...          2   \n",
       "2193      1Fam      1.5Fin             5             4  ...          1   \n",
       "2194      1Fam      2Story             7             5  ...          2   \n",
       "2195      1Fam      1Story             5             5  ...          1   \n",
       "2196      1Fam      2Story             8             5  ...          2   \n",
       "\n",
       "     Half Bath Bedroom AbvGr TotRms AbvGrd Gr Liv Area  Functional  \\\n",
       "0            1             3             6        1218         Typ   \n",
       "1            0             3             7        2196         Typ   \n",
       "2            0             3             7        1344         Typ   \n",
       "3            0             2             6        1456         Typ   \n",
       "4            1             3             7        1374         Typ   \n",
       "...        ...           ...           ...         ...         ...   \n",
       "2192         1             3             8        1915         Typ   \n",
       "2193         1             3             7        1268         Typ   \n",
       "2194         1             4             8        2322         Typ   \n",
       "2195         0             2             5         835         Typ   \n",
       "2196         1             4            10        2088         Typ   \n",
       "\n",
       "      Screen Porch  Pool Area  Yr Sold  Sale Type  \n",
       "0                0          0     2009         WD  \n",
       "1                0          0     2009         WD  \n",
       "2              233          0     2009        COD  \n",
       "3                0          0     2009         WD  \n",
       "4                0          0     2009         WD  \n",
       "...            ...        ...      ...        ...  \n",
       "2192             0          0     2006         WD  \n",
       "2193             0          0     2009         WD  \n",
       "2194             0          0     2008         WD  \n",
       "2195             0          0     2010        COD  \n",
       "2196             0          0     2008         WD  \n",
       "\n",
       "[2196 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_clean = house_raw.dropna()\n",
    "house_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Must convert SalePrice to log(SalePrice) before creating any models, then find the RMSE using the log(y_pred) from the test data to find the RMSE, then convert the log(y_pred) back to regular dollars by exponentiating it for the final test data CSV predictions on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_18444\\2367813105.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  house_clean['LogSalePrice'] = np.log(house_clean['SalePrice'])\n"
     ]
    }
   ],
   "source": [
    "# converting SalesPrice into log(SalePrice)\n",
    "house_clean['LogSalePrice'] = np.log(house_clean['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>PID</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>...</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>LogSalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159000</td>\n",
       "      <td>531363010</td>\n",
       "      <td>80.00</td>\n",
       "      <td>9605</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1218</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>11.976659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271900</td>\n",
       "      <td>906203120</td>\n",
       "      <td>90.00</td>\n",
       "      <td>14684</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2196</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>12.513190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137500</td>\n",
       "      <td>916176030</td>\n",
       "      <td>90.13</td>\n",
       "      <td>14375</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Timber</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1344</td>\n",
       "      <td>Typ</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>11.831379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248500</td>\n",
       "      <td>528180130</td>\n",
       "      <td>48.00</td>\n",
       "      <td>6472</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>1Story</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1456</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>12.423198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167000</td>\n",
       "      <td>528290030</td>\n",
       "      <td>61.00</td>\n",
       "      <td>9734</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1374</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>12.025749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>220000</td>\n",
       "      <td>906420020</td>\n",
       "      <td>80.00</td>\n",
       "      <td>10041</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1915</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>12.301383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>160000</td>\n",
       "      <td>909129090</td>\n",
       "      <td>70.00</td>\n",
       "      <td>6300</td>\n",
       "      <td>Pave</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1268</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>11.982929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>225000</td>\n",
       "      <td>528292060</td>\n",
       "      <td>41.00</td>\n",
       "      <td>12460</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2322</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>12.323856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>83000</td>\n",
       "      <td>905426060</td>\n",
       "      <td>85.00</td>\n",
       "      <td>10625</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>835</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>COD</td>\n",
       "      <td>11.326596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>250000</td>\n",
       "      <td>528142020</td>\n",
       "      <td>74.00</td>\n",
       "      <td>8899</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2088</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice        PID  Lot Frontage  Lot Area Street Neighborhood  \\\n",
       "0        159000  531363010         80.00      9605   Pave      SawyerW   \n",
       "1        271900  906203120         90.00     14684   Pave      SawyerW   \n",
       "2        137500  916176030         90.13     14375   Pave       Timber   \n",
       "3        248500  528180130         48.00      6472   Pave      NridgHt   \n",
       "4        167000  528290030         61.00      9734   Pave      Gilbert   \n",
       "...         ...        ...           ...       ...    ...          ...   \n",
       "2192     220000  906420020         80.00     10041   Pave      SawyerW   \n",
       "2193     160000  909129090         70.00      6300   Pave        SWISU   \n",
       "2194     225000  528292060         41.00     12460   Pave      Gilbert   \n",
       "2195      83000  905426060         85.00     10625   Pave      Edwards   \n",
       "2196     250000  528142020         74.00      8899   Pave      NridgHt   \n",
       "\n",
       "     Bldg Type House Style  Overall Qual  Overall Cond  ...  Half Bath  \\\n",
       "0         1Fam      1Story             7             6  ...          1   \n",
       "1         1Fam      1Story             7             7  ...          0   \n",
       "2         1Fam        SLvl             6             6  ...          0   \n",
       "3       TwnhsE      1Story             9             5  ...          0   \n",
       "4         1Fam        SLvl             7             5  ...          1   \n",
       "...        ...         ...           ...           ...  ...        ...   \n",
       "2192      1Fam      2Story             8             5  ...          1   \n",
       "2193      1Fam      1.5Fin             5             4  ...          1   \n",
       "2194      1Fam      2Story             7             5  ...          1   \n",
       "2195      1Fam      1Story             5             5  ...          0   \n",
       "2196      1Fam      2Story             8             5  ...          1   \n",
       "\n",
       "     Bedroom AbvGr TotRms AbvGrd Gr Liv Area Functional  Screen Porch  \\\n",
       "0                3             6        1218        Typ             0   \n",
       "1                3             7        2196        Typ             0   \n",
       "2                3             7        1344        Typ           233   \n",
       "3                2             6        1456        Typ             0   \n",
       "4                3             7        1374        Typ             0   \n",
       "...            ...           ...         ...        ...           ...   \n",
       "2192             3             8        1915        Typ             0   \n",
       "2193             3             7        1268        Typ             0   \n",
       "2194             4             8        2322        Typ             0   \n",
       "2195             2             5         835        Typ             0   \n",
       "2196             4            10        2088        Typ             0   \n",
       "\n",
       "      Pool Area  Yr Sold  Sale Type  LogSalePrice  \n",
       "0             0     2009         WD     11.976659  \n",
       "1             0     2009         WD     12.513190  \n",
       "2             0     2009        COD     11.831379  \n",
       "3             0     2009         WD     12.423198  \n",
       "4             0     2009         WD     12.025749  \n",
       "...         ...      ...        ...           ...  \n",
       "2192          0     2006         WD     12.301383  \n",
       "2193          0     2009         WD     11.982929  \n",
       "2194          0     2008         WD     12.323856  \n",
       "2195          0     2010        COD     11.326596  \n",
       "2196          0     2008         WD     12.429216  \n",
       "\n",
       "[2196 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Ridge Model with all predictors\n",
    "For this and all following models, RMSE is used as Kaggle's preferred model evaluation metric. I have chosen to use a grid search method to tune hyperparameters of each chosen model with their given predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ridge__alpha': 10, 'ridge__fit_intercept': True, 'ridge__solver': 'sparse_cg', 'ridge__tol': 0.001}\n",
      "Best RMSE Score: 0.14857858925547804\n"
     ]
    }
   ],
   "source": [
    "# ridge regression with all predictors\n",
    "from sklearn.linear_model import Ridge\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice'], axis=1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "# Define the ColumnTransformer for preprocessing\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'), \n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Define the pipeline with Ridge Regression\n",
    "ridge_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('ridge', Ridge(max_iter=10000, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for Ridge\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'ridge__fit_intercept': [True, False],          # Whether to calculate the intercept\n",
    "    'ridge__tol': [1e-4, 1e-3, 1e-2],              # Tolerance for optimization\n",
    "    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solvers\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge model without 'totrms abvgrd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ridge__alpha': 10, 'ridge__fit_intercept': True, 'ridge__solver': 'lsqr', 'ridge__tol': 0.001}\n",
      "Best RMSE Score: 0.1484600298822546\n"
     ]
    }
   ],
   "source": [
    "# ridge regression without 1. totrms abvgrd\n",
    "# ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice', 'TotRms AbvGrd'], axis=1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "# Define the ColumnTransformer for preprocessing\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'), \n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Define the pipeline with Ridge Regression\n",
    "ridge_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('ridge', Ridge(max_iter=10000, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for Ridge\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'ridge__fit_intercept': [True, False],          # Whether to calculate the intercept\n",
    "    'ridge__tol': [1e-4, 1e-3, 1e-2],              # Tolerance for optimization\n",
    "    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solvers\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge model with less predictor variables (SECOND BEST MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ridge__alpha': 10, 'ridge__fit_intercept': True, 'ridge__solver': 'sparse_cg', 'ridge__tol': 0.001}\n",
      "Best RMSE Score: 0.14706169609551506\n"
     ]
    }
   ],
   "source": [
    "# ridge regression without totrms abvgrd and lot frontage and pool area\n",
    "from sklearn.linear_model import Ridge\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice', 'TotRms AbvGrd', 'Lot Frontage', 'Pool Area',], axis=1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "# Define the ColumnTransformer for preprocessing\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'), \n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Define the pipeline with Ridge Regression\n",
    "best_ridge_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('ridge', Ridge(max_iter=10000, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for Ridge\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'ridge__fit_intercept': [True, False],          # Whether to calculate the intercept\n",
    "    'ridge__tol': [1e-4, 1e-3, 1e-2],              # Tolerance for optimization\n",
    "    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solvers\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(best_ridge_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting prediction CSV for Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>907135180</td>\n",
       "      <td>11.770305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528181040</td>\n",
       "      <td>12.300574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528175010</td>\n",
       "      <td>12.300769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531379030</td>\n",
       "      <td>12.128099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>923275090</td>\n",
       "      <td>11.764799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>528174060</td>\n",
       "      <td>12.114607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>903400180</td>\n",
       "      <td>12.050217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>903227150</td>\n",
       "      <td>11.793525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>909250070</td>\n",
       "      <td>11.967114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>909425180</td>\n",
       "      <td>12.204391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PID  SalePrice\n",
       "0    907135180  11.770305\n",
       "1    528181040  12.300574\n",
       "2    528175010  12.300769\n",
       "3    531379030  12.128099\n",
       "4    923275090  11.764799\n",
       "..         ...        ...\n",
       "600  528174060  12.114607\n",
       "601  903400180  12.050217\n",
       "602  903227150  11.793525\n",
       "603  909250070  11.967114\n",
       "604  909425180  12.204391\n",
       "\n",
       "[605 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting dataframe with predictions for this ^ model \n",
    "test_house_data = pd.read_csv(\"C:/Users/alexa/OneDrive/Documentos/VSCode Folder/GSB544_Computing_and_ML/Kaggle_Comp/Data/test_new.csv\")\n",
    "test_house_data \n",
    "\n",
    "best_ridge_pipeline.fit(X, y)\n",
    "\n",
    "\n",
    "final_predictions = pd.DataFrame(\n",
    "    {\"PID\": test_house_data['PID'],\n",
    "    \"SalePrice\": best_ridge_pipeline.predict(test_house_data)}\n",
    ")\n",
    "\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>907135180</td>\n",
       "      <td>129353.545104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528181040</td>\n",
       "      <td>219822.183821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528175010</td>\n",
       "      <td>219865.008445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531379030</td>\n",
       "      <td>184997.795732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>923275090</td>\n",
       "      <td>128643.388511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>528174060</td>\n",
       "      <td>182518.473143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>903400180</td>\n",
       "      <td>171136.567154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>903227150</td>\n",
       "      <td>132392.284439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>909250070</td>\n",
       "      <td>157489.450688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>909425180</td>\n",
       "      <td>199663.865530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PID      SalePrice\n",
       "0    907135180  129353.545104\n",
       "1    528181040  219822.183821\n",
       "2    528175010  219865.008445\n",
       "3    531379030  184997.795732\n",
       "4    923275090  128643.388511\n",
       "..         ...            ...\n",
       "600  528174060  182518.473143\n",
       "601  903400180  171136.567154\n",
       "602  903227150  132392.284439\n",
       "603  909250070  157489.450688\n",
       "604  909425180  199663.865530\n",
       "\n",
       "[605 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponentiating log values to get prediction in dollars\n",
    "final_predictions['SalePrice'] = np.exp(final_predictions['SalePrice'])\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge model with unimportant predictor variables and exponentiated 'Gr Liv Area' (BEST MODEL)\n",
    "Here I decided to exponentiate Gr Liv Area to further standardize it. It would make sense that Gr Liv Area might not have a linear relationship with Sale Price since there might be diminishing OR accelerating returns on larger properties. Exponentiating this variable results in an exponentially larger or smaller impact on price depending on the observation. Additionally, Gr Liv Area has a right skewed distribution (as is common with size-related metrics like square feet) according to the Data Wrangler extension, which exponentiating helps to make more normal. These reasons are why this is the best model for predicting Sale Price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ridge__alpha': 10, 'ridge__fit_intercept': True, 'ridge__solver': 'lsqr', 'ridge__tol': 0.001}\n",
      "Best RMSE Score: 0.13528459066091847\n"
     ]
    }
   ],
   "source": [
    "# ridge with polynomials\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice', 'TotRms AbvGrd', 'Lot Frontage', 'Pool Area',], axis=1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'), \n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "ct_poly = ColumnTransformer([\n",
    "    ('squared', PolynomialFeatures(degree = 2, include_bias=False), ['standardize__Gr Liv Area'])], remainder='passthrough'\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "# Define the pipeline with Ridge Regression\n",
    "poly_ridge_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('poly', ct_poly),\n",
    "        ('ridge', Ridge(max_iter=10000, random_state=42))\n",
    "    ]\n",
    ")\n",
    "# ct_poly.fit_transform(ct.fit_transform(X))\n",
    "\n",
    "\n",
    "# Define the parameter grid for Ridge\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'ridge__fit_intercept': [True, False],          # Whether to calculate the intercept\n",
    "    'ridge__tol': [1e-4, 1e-3, 1e-2],              # Tolerance for optimization\n",
    "    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solvers\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(poly_ridge_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>907135180</td>\n",
       "      <td>11.727208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528181040</td>\n",
       "      <td>12.305747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528175010</td>\n",
       "      <td>12.302247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531379030</td>\n",
       "      <td>12.163736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>923275090</td>\n",
       "      <td>11.697161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>528174060</td>\n",
       "      <td>12.128654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>903400180</td>\n",
       "      <td>12.071290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>903227150</td>\n",
       "      <td>11.775040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>909250070</td>\n",
       "      <td>12.007623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>909425180</td>\n",
       "      <td>12.261445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PID  SalePrice\n",
       "0    907135180  11.727208\n",
       "1    528181040  12.305747\n",
       "2    528175010  12.302247\n",
       "3    531379030  12.163736\n",
       "4    923275090  11.697161\n",
       "..         ...        ...\n",
       "600  528174060  12.128654\n",
       "601  903400180  12.071290\n",
       "602  903227150  11.775040\n",
       "603  909250070  12.007623\n",
       "604  909425180  12.261445\n",
       "\n",
       "[605 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting dataframe with predictions for this ^ model \n",
    "test_house_data = pd.read_csv(\"C:/Users/alexa/OneDrive/Documentos/VSCode Folder/GSB544_Computing_and_ML/Kaggle_Comp/Data/test_new.csv\")\n",
    "test_house_data \n",
    "\n",
    "poly_ridge_pipeline.fit(X, y)\n",
    "\n",
    "\n",
    "final_ridgepoly_predictions = pd.DataFrame(\n",
    "    {\"PID\": test_house_data['PID'],\n",
    "    \"SalePrice\": poly_ridge_pipeline.predict(test_house_data)}\n",
    ")\n",
    "\n",
    "final_ridgepoly_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>907135180</td>\n",
       "      <td>123897.250511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528181040</td>\n",
       "      <td>220962.172153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528175010</td>\n",
       "      <td>220190.289025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531379030</td>\n",
       "      <td>191709.452575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>923275090</td>\n",
       "      <td>120229.894498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>528174060</td>\n",
       "      <td>185100.488474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>903400180</td>\n",
       "      <td>174781.210486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>903227150</td>\n",
       "      <td>129967.536821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>909250070</td>\n",
       "      <td>164000.278748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>909425180</td>\n",
       "      <td>211386.807560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PID      SalePrice\n",
       "0    907135180  123897.250511\n",
       "1    528181040  220962.172153\n",
       "2    528175010  220190.289025\n",
       "3    531379030  191709.452575\n",
       "4    923275090  120229.894498\n",
       "..         ...            ...\n",
       "600  528174060  185100.488474\n",
       "601  903400180  174781.210486\n",
       "602  903227150  129967.536821\n",
       "603  909250070  164000.278748\n",
       "604  909425180  211386.807560\n",
       "\n",
       "[605 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponentiating log values to get prediction in dollars\n",
    "final_ridgepoly_predictions['SalePrice'] = np.exp(final_ridgepoly_predictions['SalePrice'])\n",
    "final_ridgepoly_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional ridge regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ridge__alpha': 10, 'ridge__fit_intercept': True, 'ridge__solver': 'sparse_cg', 'ridge__tol': 0.001}\n",
      "Best RMSE Score: 0.14716252201866173\n"
     ]
    }
   ],
   "source": [
    "# ridge regression without totrms abvgrd and lot frontage and pool area and half bath\n",
    "from sklearn.linear_model import Ridge\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice', 'TotRms AbvGrd', 'Lot Frontage', 'Pool Area', 'Half Bath'], axis=1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "# Define the ColumnTransformer for preprocessing\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'), \n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Define the pipeline with Ridge Regression\n",
    "ridge_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('ridge', Ridge(max_iter=10000, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for Ridge\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'ridge__fit_intercept': [True, False],          # Whether to calculate the intercept\n",
    "    'ridge__tol': [1e-4, 1e-3, 1e-2],              # Tolerance for optimization\n",
    "    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solvers\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ridge__alpha': 10, 'ridge__fit_intercept': True, 'ridge__solver': 'lsqr', 'ridge__tol': 0.001}\n",
      "Best RMSE Score: 0.14794094944083272\n"
     ]
    }
   ],
   "source": [
    "# ridge regression without totrms abvgrd and lot frontage and half bath\n",
    "from sklearn.linear_model import Ridge\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice', 'TotRms AbvGrd', 'Lot Frontage', 'Half Bath'], axis=1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "# Define the ColumnTransformer for preprocessing\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'), \n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Define the pipeline with Ridge Regression\n",
    "ridge_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('ridge', Ridge(max_iter=10000, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for Ridge\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'ridge__fit_intercept': [True, False],          # Whether to calculate the intercept\n",
    "    'ridge__tol': [1e-4, 1e-3, 1e-2],              # Tolerance for optimization\n",
    "    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],  # Solvers\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(ridge_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lasso__alpha': 0.001, 'lasso__fit_intercept': True, 'lasso__selection': 'random', 'lasso__tol': 0.01}\n",
      "Best RMSE Score: 0.1512820204376578\n"
     ]
    }
   ],
   "source": [
    "# lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice', 'TotRms AbvGrd', 'Yr Sold', 'Half Bath'], axis = 1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "lasso_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('lasso', Lasso(max_iter=10000, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.001, 0.01, 0.1, 1, 10],   # Regularization strength\n",
    "    'lasso__fit_intercept': [True, False],       # Whether to calculate the intercept\n",
    "    'lasso__tol': [1e-4, 1e-3, 1e-2],           # Tolerance for optimization\n",
    "    'lasso__selection': ['cyclic', 'random'],    # Coordinate descent strategy\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(lasso_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient analysis for aboce lasso refression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Absolute_Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummify__Street_Grvl</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummify__Street_Pave</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummify__Neighborhood_Blmngtn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummify__Neighborhood_Blueste</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dummify__Neighborhood_BrDale</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>standardize__Full Bath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>standardize__Bedroom AbvGr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>standardize__Gr Liv Area</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>standardize__Screen Porch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>standardize__Pool Area</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature  Coefficient  Absolute_Coefficient\n",
       "0            dummify__Street_Grvl         -0.0                   0.0\n",
       "1            dummify__Street_Pave          0.0                   0.0\n",
       "2   dummify__Neighborhood_Blmngtn          0.0                   0.0\n",
       "3   dummify__Neighborhood_Blueste         -0.0                   0.0\n",
       "4    dummify__Neighborhood_BrDale         -0.0                   0.0\n",
       "..                            ...          ...                   ...\n",
       "85         standardize__Full Bath          0.0                   0.0\n",
       "86     standardize__Bedroom AbvGr          0.0                   0.0\n",
       "87       standardize__Gr Liv Area          0.0                   0.0\n",
       "88      standardize__Screen Porch          0.0                   0.0\n",
       "89         standardize__Pool Area          0.0                   0.0\n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the data\n",
    "lasso_pipeline.fit(X, y)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = lasso_pipeline.named_steps[\"preprocessing\"].get_feature_names_out()\n",
    "\n",
    "# Get coefficients from the Ridge model\n",
    "lasso_coefs = lasso_pipeline.named_steps[\"lasso\"].coef_\n",
    "\n",
    "# Map coefficients to their corresponding feature names\n",
    "coefficients = dict(zip(feature_names, lasso_coefs))\n",
    "\n",
    "# Create a DataFrame for the coefficients\n",
    "coefficients_df = pd.DataFrame(list(coefficients.items()), columns=['Feature', 'Coefficient'])\n",
    "\n",
    "# Sort coefficients by absolute value for better readability\n",
    "coefficients_df['Absolute_Coefficient'] = coefficients_df['Coefficient'].abs()\n",
    "coefficients_df = coefficients_df.sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "\n",
    "# Display the sorted coefficients\n",
    "coefficients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'elastic__alpha': 0.001, 'elastic__copy_X': True, 'elastic__l1_ratio': 0.2, 'elastic__positive': False, 'elastic__selection': 'random', 'elastic__tol': 0.01}\n",
      "Best RMSE Score: 0.14695717979195771\n"
     ]
    }
   ],
   "source": [
    "# elastic net model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "X = house_clean.drop(['SalePrice', 'PID', 'LogSalePrice', 'Lot Frontage', 'Pool Area', 'TotRms AbvGrd'], axis = 1)\n",
    "y = house_clean['LogSalePrice']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "en_pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessing', ct),\n",
    "        ('elastic', ElasticNet())  # Adjust max_iter for convergence\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for ElasticNet\n",
    "param_grid = {\n",
    "    'elastic__alpha': [0.0001, 0.001], # Regularization strength\n",
    "    'elastic__l1_ratio': [0.1, 0.2],   # Mix of L1 and L2 penalties\n",
    "    'elastic__copy_X': [True, False],                # Whether to copy the input data\n",
    "    'elastic__positive': [True, False],              # Restrict coefficients to be positive\n",
    "    'elastic__selection': ['cyclic', 'random'],      # Coordinate descent strategy\n",
    "    'elastic__tol': [1e-4, 1e-3, 1e-2, 0.01],              # Tolerance for optimization\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gscv = GridSearchCV(en_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "print(\"Best Parameters:\", gscv_fitted.best_params_)\n",
    "print(\"Best RMSE Score:\", abs(gscv_fitted.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions['SalePrice'] = np.exp(final_predictions['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>907135180</td>\n",
       "      <td>129682.268351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528181040</td>\n",
       "      <td>220706.445030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528175010</td>\n",
       "      <td>220149.167426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531379030</td>\n",
       "      <td>185343.966445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>923275090</td>\n",
       "      <td>130231.243918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>528174060</td>\n",
       "      <td>182910.859413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>903400180</td>\n",
       "      <td>171021.576376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>903227150</td>\n",
       "      <td>131768.913644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>909250070</td>\n",
       "      <td>158555.195464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>909425180</td>\n",
       "      <td>199720.717771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PID      SalePrice\n",
       "0    907135180  129682.268351\n",
       "1    528181040  220706.445030\n",
       "2    528175010  220149.167426\n",
       "3    531379030  185343.966445\n",
       "4    923275090  130231.243918\n",
       "..         ...            ...\n",
       "600  528174060  182910.859413\n",
       "601  903400180  171021.576376\n",
       "602  903227150  131768.913644\n",
       "603  909250070  158555.195464\n",
       "604  909425180  199720.717771\n",
       "\n",
       "[605 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Statement:\n",
    "ChatGPT4o assisted me in this assignment with finding coefficient values for the models in which I thought it would be useful to see coefficients for dimension reduction. It also helped with setting up a model to find predicted values for missing 'Lot Frontage' values to create a cleaned dataset for predicting SalePrice in the house dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
